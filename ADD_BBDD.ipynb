{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9e9b3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = 'C:/Users/User/Desktop/Cliodinámica/BBDD/CENSO/Personas/' #Ubicación de la base de datos y los archivos de etiqueta\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))] #Lectura de todos los archivos en la carpeta indicada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb7e29ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para eliminar acentos y dejar todo con mayusculas\n",
    "def normalize(s):\n",
    "    replacements = (\n",
    "        (\"á\", \"a\"),\n",
    "        (\"é\", \"e\"),\n",
    "        (\"í\", \"i\"),\n",
    "        (\"ó\", \"o\"),\n",
    "        (\"ú\", \"u\"),\n",
    "        (\"ä\", \"a\"),\n",
    "        (\"ë\", \"e\"),\n",
    "        (\"ï\", \"i\"),\n",
    "        (\"ö\", \"o\"),\n",
    "        (\"ü\", \"u\"),\n",
    "    )\n",
    "    for a, b in replacements:\n",
    "        s = s.replace(a, b).replace(a.upper(), b.upper())\n",
    "        s = s.upper()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b147322e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P07', 'P08', 'P10', 'P11', 'P12', 'P12A_TRAMO', 'P13', 'P15', 'P16', 'P16A', 'P16A_OTRO', 'P17']\n"
     ]
    }
   ],
   "source": [
    "loc_ind = []\n",
    "tags = []\n",
    "df_desc = pd.read_csv(mypath + \"Var_Des.csv\",sep=';')\n",
    "total_tag = list(df_desc['NOMBRE VARIABLE EN BBDD'])\n",
    "aux = 0\n",
    "for files in onlyfiles: #Por cada archivo en carpeta, cuyo listado es onlyfiles\n",
    "    if files.startswith(\"etiquetas\"): #Si comienza por la palabra etiquetas\n",
    "        tag_files = normalize(files[10:-4]) #Extraer información importante, en este caso el código de la variable\n",
    "        for des_tag in total_tag:\n",
    "            if des_tag == tag_files:\n",
    "                loc_ind.append(aux) #Identifica la ubicación del archivo que nos interesa en onlyfiles y se agrega a una lista\n",
    "                tags.append(normalize(tag_files)) #Agrega el nombre de la variable en mayusculas en una lista\n",
    "        aux += 1\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70171f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read datab\n",
    "df_censo = pd.read_csv(mypath+'Microdato_Censo2017-Personas.csv',sep=';') #Lectura de la base de datos de CENSO\n",
    "#Crea un diccionario con varios dataframes, compuesto por la comuna y la variable que nos interesa\n",
    "#De acerudo a la lista 'tags' creada anteriormente\n",
    "d = {'df_' + i: df_censo[['COMUNA', i]] for i in tags} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86b44157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "etiquetas_p08.csv\n"
     ]
    }
   ],
   "source": [
    "largo = list(range(0,len(tags)))\n",
    "print(largo)\n",
    "#Crea un diccionario con todas las etiquetas extraídas desde la carpeta\n",
    "print(onlyfiles[loc_ind[1]])\n",
    "et = {'et_' + tags[i]: pd.read_csv(mypath + onlyfiles[loc_ind[i]],sep=';') for i in largo} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ce5be65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COMUNA  P10\n",
       "1101    1      179107\n",
       "        2        9752\n",
       "        3       12939\n",
       "        4        5068\n",
       "        99     188595\n",
       "                ...  \n",
       "16305   1       11052\n",
       "        2         160\n",
       "        3        1140\n",
       "        4          12\n",
       "        99       8712\n",
       "Name: P10, Length: 1712, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_censo.groupby([\"COMUNA\",\"P10\"])[\"P10\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1172eef4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\series.py:4509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n"
     ]
    }
   ],
   "source": [
    "df_name = ['df_'+ name for name in tags]\n",
    "et_name = ['et_'+ name for name in tags]\n",
    "for i in largo:    \n",
    "    val = list(et[et_name[i]]['valor'])\n",
    "    glo = list(et[et_name[i]]['glosa']+ ' ' + tags[i])\n",
    "    d[df_name[i]][tags[i]].replace(val,glo,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c1d27b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COMUNA  P16A_OTRO                            \n",
       "1101    Afrodescendiente P16A_OTRO                  308\n",
       "        Changos P16A_OTRO                            72\n",
       "        Chonos P16A_OTRO                              3\n",
       "        Huilliche P16A_OTRO                          43\n",
       "        Missing P16A_OTRO                          4183\n",
       "        No aplica P16A_OTRO                      185532\n",
       "        Ona P16A_OTRO                                 5\n",
       "        Pehuenche P16A_OTRO                           8\n",
       "        Picunche P16A_OTRO                            3\n",
       "        Pueblo no declarado P16A_OTRO               856\n",
       "        Pueblos de América Latina P16A_OTRO         421\n",
       "        Pueblos del resto del mundo P16A_OTRO        32\n",
       "        Tehuelches P16A_OTRO                          2\n",
       "11101   Afrodescendiente P16A_OTRO                    8\n",
       "        Chonos P16A_OTRO                             11\n",
       "        Huilliche P16A_OTRO                         616\n",
       "        Missing P16A_OTRO                          1026\n",
       "        No aplica P16A_OTRO                       55675\n",
       "        Ona P16A_OTRO                                 6\n",
       "        Pehuenche P16A_OTRO                          10\n",
       "        Picunche P16A_OTRO                            1\n",
       "        Pueblo no declarado P16A_OTRO               339\n",
       "        Pueblos de América Latina P16A_OTRO          19\n",
       "        Pueblos del resto del mundo P16A_OTRO         4\n",
       "        Tehuelches P16A_OTRO                        103\n",
       "Name: P16A_OTRO, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"df_P16A_OTRO\"].groupby([\"COMUNA\",\"P16A_OTRO\"])[\"P16A_OTRO\"].count().filter(like=\"1101\", axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63b5110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_desc = []\n",
    "for i in largo:\n",
    "    desc_list =[]\n",
    "    name_var = df_desc['NOMBRE VARIABLE EN BBDD'][i]\n",
    "    var = df_desc['VARIABLE'][i]\n",
    "    subdim = df_desc['SUBDIMENSIÓN'][i]\n",
    "    dim = df_desc['DIMENSIÓN'][i]\n",
    "    fuente = \"CENSO PERSONAS\"\n",
    "    year = \"2017\"\n",
    "    desc = df_desc['DESCRIPCIÓN'][i]\n",
    "    val = list(et[et_name[i]]['glosa'])\n",
    "    alc = \"COMUNA\"\n",
    "    for etiqueta in val:\n",
    "        desc_list = [dim, subdim, var, etiqueta, desc, name_var, fuente, year, alc]\n",
    "        mat_desc.append(desc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "878766c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat_name = ['dat_'+ name for name in tags]\n",
    "dat = {'dat_' + tags[i]: d[df_name[i]].groupby(['COMUNA',tags[i]]).size().unstack(fill_value=0) for i in largo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e1d02d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat(dat.values(),axis = 1)\n",
    "df.columns[5].startswith(\"H\")\n",
    "for columna in df.columns:\n",
    "    if columna.startswith(\"Missing\") or columna.startswith(\"No aplica\"):\n",
    "        df.drop(columna, inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c8cfb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo archivos complementarios...\n"
     ]
    }
   ],
   "source": [
    "cod_com = 'Test_CUT.csv'\n",
    "#Read data\n",
    "print('Leyendo archivos complementarios...')\n",
    "df_comuna = pd.read_csv(mypath+cod_com,sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a675471a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estandarizando nombres de comunas...\n",
      "Reemplazando nombres por códigos únicos territoriales...\n",
      "Listo!\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def comunal(DF,df_comuna):   \n",
    "    print(\"Estandarizando nombres de comunas...\")\n",
    "    comuna = \"COMUNA\"\n",
    "    DF = DF.reset_index()\n",
    "    DF[comuna] = DF[comuna].apply(str)\n",
    "    DF[comuna] = [normalize(x) for x in DF[comuna]]\n",
    "    df_comuna[\"cod_com\"] =df_comuna[\"cod_com\"].apply(str) \n",
    "    codigo, nombre = df_comuna.columns\n",
    "    codigo = list(df_comuna[codigo])\n",
    "    nombre = list(df_comuna[nombre])\n",
    "    filas, columnas = DF.shape\n",
    "    print(\"Reemplazando nombres por códigos únicos territoriales...\")\n",
    "    DF[comuna].replace(\"CALERA\",\"LA CALERA\",inplace=True)\n",
    "    DF[comuna].replace(\"PAIGUANO\",\"PAIHUANO\",inplace=True)\n",
    "    DF[comuna].replace(nombre,codigo,inplace=True)\n",
    "    df_comuna = df_comuna.set_index('cod_com')\n",
    "    DF = DF.set_index(comuna)\n",
    "    DF = pd.concat([df_comuna,DF.reindex(df_comuna.index)],axis=1)\n",
    "    DF = DF.drop(columns = \"nom_com\")\n",
    "    DF = DF.where(pd.notnull(DF), None)\n",
    "    print(\"Listo!\")\n",
    "    print(\"  \")\n",
    "    return DF\n",
    "df = comunal(df,df_comuna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7358e85c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_data = []\n",
    "for var in (tags):\n",
    "    for name_col in df.columns:\n",
    "        for x in mat_desc:\n",
    "            if var == name_col[-len(var):] and name_col[:-(len(var)+1)]==x[3]:\n",
    "                data = (x + list(df[name_col]))\n",
    "                list_data.append(data)  \n",
    "aux = len(list_data)\n",
    "for i in range(aux):\n",
    "    for j in range(8):\n",
    "        list_data[i][j] = (list_data[i][j]).upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f98b3405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n"
     ]
    }
   ],
   "source": [
    "path_matrix = 'C:/Users/User/Desktop/Cliodinámica/BBDD/CENSO/Personas/'\n",
    "only_matrix = [f for f in listdir(path_matrix) if isfile(join(path_matrix, f))]\n",
    "df_matrix = pd.read_csv(path_matrix+'Matriz_Consulta.csv',sep=';')\n",
    "print(len(list_data))\n",
    "df_nueva = df_matrix\n",
    "for lista in list_data:\n",
    "    df_nueva = df_nueva.append(pd.Series(lista, index = df_nueva.columns), ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a0e5bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nueva.to_csv(\"Matriz_consulta_N.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3db1af43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nueva.to_excel(\"Matriz_consulta_N.xlsx\", encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefd51bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
